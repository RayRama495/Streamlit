# -*- coding: utf-8 -*-
"""UAS_A11.2021.13850_Bengkod.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1NJ-DT1cG9nMWmspEs1LrhyqgOaUzpi5L
"""

import numpy as np
from scipy import stats
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import StandardScaler
from sklearn.impute import SimpleImputer
from sklearn.naive_bayes import GaussianNB
from sklearn.metrics import classification_report, confusion_matrix
from sklearn.metrics import accuracy_score
from sklearn.preprocessing import StandardScaler
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier

file_path = ('/content/water_potability.csv')
water_data = pd.read_csv(file_path)

water_data.head()

df=water_data.copy()

"""2. Lakukan analisis awal terhadap 10 kolom dari dataset, yang terdiri dari: Ph, Hardness, Solids,
Chloramines, Sulfate, Conductivity, Organic_carbon, Trihalomethanes, Turbidity, dan
Potabiliy. Tampilkan informasi dari dataset, seperti jumlah baris, tipe data tiap kolom, dan
nilai unik.
"""

water_data.info()

print ("Jumlah baris : ",water_data.shape[0])

water_data.dtypes

water_data.nunique()

water_data.isnull().sum()

# Menghitung Z-Score
z_scores = stats.zscore(df.select_dtypes(include=['float64', 'int64']))

# Menentukan batas Z-Score (misalnya > 3 atau < -3)
outliers_zscore = (z_scores > 3) | (z_scores < -3)

# Menampilkan jumlah outlier per kolom
print("Jumlah outlier berdasarkan Z-Score:")
print(outliers_zscore.sum())

numerical_columns = df.select_dtypes(include=['float64', 'int64']).columns
df[numerical_columns] = df[numerical_columns].fillna(df[numerical_columns].mean())

# Memeriksa apakah masih ada missing values setelah imputasi
missing_values_after = df.isnull().sum()
print("\nJumlah missing values setelah imputasi rata-rata:")
print(missing_values_after)

# Memeriksa apakah masih ada missing values
if df.isnull().sum().sum() == 0:
    print("\nImputasi berhasil, tidak ada missing values yang tersisa.")
else:
    print("\nMasih ada missing values setelah imputasi.")

from imblearn.over_sampling import SMOTE

# Memisahkan fitur (X) dan target (y)
X = df.drop('Potability', axis=1)
y = df['Potability']

# Menggunakan SMOTE untuk oversampling kelas minoritas
smote = SMOTE(random_state=42)
X_resampled, y_resampled = smote.fit_resample(X, y)

# Menyusun ulang DataFrame setelah resampling
df_resampled = pd.DataFrame(X_resampled, columns=X.columns)
df_resampled['Potability'] = y_resampled

# Visualisasi distribusi 'Potability' setelah resampling
plt.figure(figsize=(8, 6))
sns.countplot(x='Potability', data=df_resampled)
plt.title('Distribusi Potability Setelah Resampling')
plt.xlabel('Potability (0 = Tidak Dapat Diminum, 1 = Dapat Diminum)')
plt.ylabel('Jumlah')
plt.show()

# Membuat plot untuk membandingkan distribusi sebelum dan setelah resampling
fig, axes = plt.subplots(1, 2, figsize=(14, 6))

# Sebelum resampling
sns.countplot(x='Potability', data=df, ax=axes[0])
axes[0].set_title('Distribusi Potability Sebelum Resampling')
axes[0].set_xlabel('Potability (0 = Tidak Dapat Diminum, 1 = Dapat Diminum)')
axes[0].set_ylabel('Jumlah')

# Setelah resampling
sns.countplot(x='Potability', data=df_resampled, ax=axes[1])
axes[1].set_title('Distribusi Potability Setelah Resampling')
axes[1].set_xlabel('Potability (0 = Tidak Dapat Diminum, 1 = Dapat Diminum)')
axes[1].set_ylabel('Jumlah')

plt.tight_layout()
plt.show()

# Menghitung korelasi antar kolom numerik
correlation_matrix = df.corr()

# Membuat heatmap untuk visualisasi korelasi antar atribut
plt.figure(figsize=(12, 8))
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f', cbar=True)
plt.title('Korelasi Antar Atribut')
plt.show()

# Membagi menjadi dua bagian
set_1 = numerical_columns[:5]
set_2 = numerical_columns[5:]

# Set 1
plt.figure(figsize=(15, 12))
for i, col in enumerate(set_1, 1):
    plt.subplot(2, 3, i)
    sns.histplot(df[col], kde=True, bins=20)
    plt.title(f'Distribusi {col}')

plt.tight_layout()
plt.show()

# Set 2
plt.figure(figsize=(15, 12))
for i, col in enumerate(set_2, 1):
    plt.subplot(2, 3, i)
    sns.histplot(df[col], kde=True, bins=20)
    plt.title(f'Distribusi {col}')

plt.tight_layout()
plt.show()

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=0)

# Membuat model Gaussian Naive Bayes
gnb = GaussianNB()
gnb.fit(X_train, y_train)

# Prediksi dan evaluasi model
y_pred_gnb = gnb.predict(X_test)
accuracy_gnb = accuracy_score(y_test, y_pred_gnb)
conf_matrix_gnb = confusion_matrix(y_test, y_pred_gnb)

print(f"Akurasi Gaussian Naive Bayes: {accuracy_gnb:.4f}")
print("Confusion Matrix Gaussian Naive Bayes:")
print(conf_matrix_gnb)

# Membuat model Decision Tree
dt = DecisionTreeClassifier(random_state=42)
dt.fit(X_train, y_train)

# Prediksi dan evaluasi model
y_pred_dt = dt.predict(X_test)
accuracy_dt = accuracy_score(y_test, y_pred_dt)
conf_matrix_dt = confusion_matrix(y_test, y_pred_dt)

print(f"Akurasi Decision Tree: {accuracy_dt:.4f}")
print("Confusion Matrix Decision Tree:")
print(conf_matrix_dt)

knn = KNeighborsClassifier(n_neighbors=5)
knn.fit(X_train, y_train)

y_pred_knn = knn.predict(X_test)
accuracy_knn = accuracy_score(y_test, y_pred_knn)
conf_matrix_knn = confusion_matrix(y_test, y_pred_knn)

print(f"Akurasi K-Nearest Neighbors: {accuracy_knn:.4f}")
print("Confusion Matrix K-Nearest Neighbors:")
print(conf_matrix_knn)

import matplotlib.pyplot as plt
import seaborn as sns

fig, axes = plt.subplots(1, 3, figsize=(18, 6))

sns.heatmap(conf_matrix_gnb, annot=True, fmt='d', cmap='Blues', ax=axes[0])
axes[0].set_title('Confusion Matrix Gaussian Naive Bayes')
axes[0].set_xlabel('Predicted')
axes[0].set_ylabel('Actual')

sns.heatmap(conf_matrix_dt, annot=True, fmt='d', cmap='Blues', ax=axes[1])
axes[1].set_title('Confusion Matrix Decision Tree')
axes[1].set_xlabel('Predicted')
axes[1].set_ylabel('Actual')

sns.heatmap(conf_matrix_knn, annot=True, fmt='d', cmap='Blues', ax=axes[2])
axes[2].set_title('Confusion Matrix K-Nearest Neighbors')
axes[2].set_xlabel('Predicted')
axes[2].set_ylabel('Actual')

plt.tight_layout()
plt.show()

# Misalnya, X adalah fitur dan y adalah target
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=42)

# Tanpa normalisasi (Model asli)
# Inisialisasi model
gnb = GaussianNB()
dt = DecisionTreeClassifier(random_state=42)
knn = KNeighborsClassifier(n_neighbors=5)

# Latih dan evaluasi model tanpa normalisasi
gnb.fit(X_train, y_train)
dt.fit(X_train, y_train)
knn.fit(X_train, y_train)

# Prediksi dan hitung akurasi
gnb_acc = accuracy_score(y_test, gnb.predict(X_test))
dt_acc = accuracy_score(y_test, dt.predict(X_test))
knn_acc = accuracy_score(y_test, knn.predict(X_test))

print(f"Akurasi GaussianNB tanpa normalisasi: {gnb_acc:.4f}")
print(f"Akurasi Decision Tree tanpa normalisasi: {dt_acc:.4f}")
print(f"Akurasi KNN tanpa normalisasi: {knn_acc:.4f}")
print("")

# Dengan normalisasi (menggunakan StandardScaler)
scaler = StandardScaler()

# Terapkan normalisasi pada data latih dan uji
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Latih dan evaluasi model dengan normalisasi
gnb.fit(X_train_scaled, y_train)
dt.fit(X_train_scaled, y_train)
knn.fit(X_train_scaled, y_train)

# Prediksi dan hitung akurasi setelah normalisasi
gnb_scaled_acc = accuracy_score(y_test, gnb.predict(X_test_scaled))
dt_scaled_acc = accuracy_score(y_test, dt.predict(X_test_scaled))
knn_scaled_acc = accuracy_score(y_test, knn.predict(X_test_scaled))

print(f"Akurasi GaussianNB setelah di normalisasi: {gnb_scaled_acc:.4f}")
print(f"Akurasi Decision Tree setelah di normalisasi: {dt_scaled_acc:.4f}")
print(f"Akurasi KNN setelah di normalisasi: {knn_scaled_acc:.4f}")

import streamlit as st
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.naive_bayes import GaussianNB
from sklearn.tree import DecisionTreeClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score
from sklearn.impute import SimpleImputer
import matplotlib.pyplot as plt

# Fungsi untuk menyiapkan model dan pelatihan
def prepare_model(model_type, X_train, y_train):
    if model_type == 'GaussianNB':
        model = GaussianNB()
    elif model_type == 'Decision Tree':
        model = DecisionTreeClassifier(random_state=42)
    elif model_type == 'KNN':
        model = KNeighborsClassifier()
    
    model.fit(X_train, y_train)
    return model

# Fungsi untuk menampilkan evaluasi model
def evaluate_model(model, X_test, y_test):
    y_pred = model.predict(X_test)
    accuracy = accuracy_score(y_test, y_pred)
    return accuracy

# Menginisialisasi aplikasi Streamlit
st.title("Water Quality Potability Prediction")

# Upload file CSV
uploaded_file = st.file_uploader("Pilih file CSV", type=["csv"])

if uploaded_file is not None:
    # Membaca data dari file CSV yang diupload
    data = pd.read_csv(uploaded_file)
    st.write("Dataset Kualitas Air:")
    st.write(data.head())
    
    # Menggunakan SimpleImputer untuk mengganti NaN dengan rata-rata (mean)
    imputer = SimpleImputer(strategy='mean')
    data_imputed = imputer.fit_transform(data)
    data = pd.DataFrame(data_imputed, columns=data.columns)
    
    st.write("Data setelah imputasi NaN-nya:")
    st.write(data.head())
    
    # Pastikan dataset memiliki kolom yang diinginkan
    if "Potability" in data.columns:
        # Menyiapkan data untuk pelatihan
        X = data.drop(columns=["Potability"])
        y = data["Potability"]
        
        # Membagi data menjadi training dan testing set
        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

        # Normalisasi data
        scaler = StandardScaler()
        X_train_scaled = scaler.fit_transform(X_train)
        X_test_scaled = scaler.transform(X_test)

        # Memilih model
        model_choice = st.sidebar.selectbox("Pilih Model", ['GaussianNB', 'Decision Tree', 'KNN'])

        # Pelatihan model
        st.write(f"Training Model {model_choice}...")
        model = prepare_model(model_choice, X_train_scaled, y_train)

        # Evaluasi model
        accuracy = evaluate_model(model, X_test_scaled, y_test)
        st.write(f"Akurasi Model {model_choice}: {accuracy:.4f}")

        # Fitur input untuk prediksi
        st.sidebar.header("Masukkan Fitur Baru")
        hardness = st.sidebar.slider("Hardness", float(X["Hardness"].min()), float(X["Hardness"].max()), float(X["Hardness"].mean()))
        solids = st.sidebar.slider("Solids", float(X["Solids"].min()), float(X["Solids"].max()), float(X["Solids"].mean()))
        chloramines = st.sidebar.slider("Chloramines", float(X["Chloramines"].min()), float(X["Chloramines"].max()), float(X["Chloramines"].mean()))
        sulfate = st.sidebar.slider("Sulfate", float(X["Sulfate"].min()), float(X["Sulfate"].max()), float(X["Sulfate"].mean()))
        conductivity = st.sidebar.slider("Conductivity", float(X["Conductivity"].min()), float(X["Conductivity"].max()), float(X["Conductivity"].mean()))
        organic_carbon = st.sidebar.slider("Organic_carbon", float(X["Organic_carbon"].min()), float(X["Organic_carbon"].max()), float(X["Organic_carbon"].mean()))
        trihalomethanes = st.sidebar.slider("Trihalomethanes", float(X["Trihalomethanes"].min()), float(X["Trihalomethanes"].max()), float(X["Trihalomethanes"].mean()))
        turbidity = st.sidebar.slider("Turbidity", float(X["Turbidity"].min()), float(X["Turbidity"].max()), float(X["Turbidity"].mean()))

        input_data = np.array([[hardness, solids, chloramines, sulfate, conductivity, organic_carbon, trihalomethanes, turbidity]])

        # Imputasi untuk input data baru
        input_data_imputed = imputer.transform(input_data)

        input_data_scaled = scaler.transform(input_data_imputed)

        # Prediksi menggunakan model yang dipilih
        prediction = model.predict(input_data_scaled)
        predicted_class = "Potable" if prediction[0] == 1 else "Non-Potable"
        st.sidebar.write(f"Prediksi Potabilitas: {predicted_class}")

        # Menampilkan visualisasi distribusi potabilitas
        st.write("Distribusi Potability dalam Dataset:")
        fig, ax = plt.subplots()
        data['Potability'].value_counts().plot(kind='bar', ax=ax)
        ax.set_xlabel("Potability")
        ax.set_ylabel("Count")
        st.pyplot(fig)
    
else:
    st.write("Silakan unggah file CSV untuk memulai.")
