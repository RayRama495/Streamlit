# -*- coding: utf-8 -*-
"""UAS_A11.2021.13850_Bengkod.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1NJ-DT1cG9nMWmspEs1LrhyqgOaUzpi5L
"""

import numpy as np
from scipy import stats
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import StandardScaler
from sklearn.impute import SimpleImputer
from sklearn.naive_bayes import GaussianNB
from sklearn.metrics import classification_report, confusion_matrix
from sklearn.metrics import accuracy_score
from sklearn.preprocessing import StandardScaler
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier

file_path = ('./water_potability.csv')
water_data = pd.read_csv(file_path)

water_data.head()

df=water_data.copy()

water_data.info()

print ("Jumlah baris : ",water_data.shape[0])

water_data.dtypes

water_data.nunique()

water_data.isnull().sum()

# Menghitung Z-Score
z_scores = stats.zscore(df.select_dtypes(include=['float64', 'int64']))

# Menentukan batas Z-Score (misalnya > 3 atau < -3)
outliers_zscore = (z_scores > 3) | (z_scores < -3)

# Menampilkan jumlah outlier per kolom
print("Jumlah outlier berdasarkan Z-Score:")
print(outliers_zscore.sum())

numerical_columns = df.select_dtypes(include=['float64', 'int64']).columns
df[numerical_columns] = df[numerical_columns].fillna(df[numerical_columns].mean())

# Memeriksa apakah masih ada missing values setelah imputasi
missing_values_after = df.isnull().sum()
print("\nJumlah missing values setelah imputasi rata-rata:")
print(missing_values_after)

# Memeriksa apakah masih ada missing values
if df.isnull().sum().sum() == 0:
    print("\nImputasi berhasil, tidak ada missing values yang tersisa.")
else:
    print("\nMasih ada missing values setelah imputasi.")

from imblearn.over_sampling import SMOTE

# Memisahkan fitur (X) dan target (y)
X = df.drop('Potability', axis=1)
y = df['Potability']

# Menggunakan SMOTE untuk oversampling kelas minoritas
smote = SMOTE(random_state=42)
X_resampled, y_resampled = smote.fit_resample(X, y)

# Menyusun ulang DataFrame setelah resampling
df_resampled = pd.DataFrame(X_resampled, columns=X.columns)
df_resampled['Potability'] = y_resampled

# Visualisasi distribusi 'Potability' setelah resampling
plt.figure(figsize=(8, 6))
sns.countplot(x='Potability', data=df_resampled)
plt.title('Distribusi Potability Setelah Resampling')
plt.xlabel('Potability (0 = Tidak Dapat Diminum, 1 = Dapat Diminum)')
plt.ylabel('Jumlah')
plt.show()

# Membuat plot untuk membandingkan distribusi sebelum dan setelah resampling
fig, axes = plt.subplots(1, 2, figsize=(14, 6))

# Sebelum resampling
sns.countplot(x='Potability', data=df, ax=axes[0])
axes[0].set_title('Distribusi Potability Sebelum Resampling')
axes[0].set_xlabel('Potability (0 = Tidak Dapat Diminum, 1 = Dapat Diminum)')
axes[0].set_ylabel('Jumlah')

# Setelah resampling
sns.countplot(x='Potability', data=df_resampled, ax=axes[1])
axes[1].set_title('Distribusi Potability Setelah Resampling')
axes[1].set_xlabel('Potability (0 = Tidak Dapat Diminum, 1 = Dapat Diminum)')
axes[1].set_ylabel('Jumlah')

plt.tight_layout()
plt.show()

# Menghitung korelasi antar kolom numerik
correlation_matrix = df.corr()

# Membuat heatmap untuk visualisasi korelasi antar atribut
plt.figure(figsize=(12, 8))
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f', cbar=True)
plt.title('Korelasi Antar Atribut')
plt.show()

# Membagi menjadi dua bagian
set_1 = numerical_columns[:5]
set_2 = numerical_columns[5:]

# Set 1
plt.figure(figsize=(15, 12))
for i, col in enumerate(set_1, 1):
    plt.subplot(2, 3, i)
    sns.histplot(df[col], kde=True, bins=20)
    plt.title(f'Distribusi {col}')

plt.tight_layout()
plt.show()

# Set 2
plt.figure(figsize=(15, 12))
for i, col in enumerate(set_2, 1):
    plt.subplot(2, 3, i)
    sns.histplot(df[col], kde=True, bins=20)
    plt.title(f'Distribusi {col}')

plt.tight_layout()
plt.show()

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=0)

# Membuat model Gaussian Naive Bayes
gnb = GaussianNB()
gnb.fit(X_train, y_train)

# Prediksi dan evaluasi model
y_pred_gnb = gnb.predict(X_test)
accuracy_gnb = accuracy_score(y_test, y_pred_gnb)
conf_matrix_gnb = confusion_matrix(y_test, y_pred_gnb)

print(f"Akurasi Gaussian Naive Bayes: {accuracy_gnb:.4f}")
print("Confusion Matrix Gaussian Naive Bayes:")
print(conf_matrix_gnb)

# Membuat model Decision Tree
dt = DecisionTreeClassifier(random_state=42)
dt.fit(X_train, y_train)

# Prediksi dan evaluasi model
y_pred_dt = dt.predict(X_test)
accuracy_dt = accuracy_score(y_test, y_pred_dt)
conf_matrix_dt = confusion_matrix(y_test, y_pred_dt)

print(f"Akurasi Decision Tree: {accuracy_dt:.4f}")
print("Confusion Matrix Decision Tree:")
print(conf_matrix_dt)

# Membuat model KNN
knn = KNeighborsClassifier(n_neighbors=5)
knn.fit(X_train, y_train)

# Prediksi dan evaluasi model
y_pred_knn = knn.predict(X_test)
accuracy_knn = accuracy_score(y_test, y_pred_knn)
conf_matrix_knn = confusion_matrix(y_test, y_pred_knn)

print(f"Akurasi K-Nearest Neighbors: {accuracy_knn:.4f}")
print("Confusion Matrix K-Nearest Neighbors:")
print(conf_matrix_knn)

fig, axes = plt.subplots(1, 3, figsize=(18, 6))

sns.heatmap(conf_matrix_gnb, annot=True, fmt='d', cmap='Blues', ax=axes[0])
axes[0].set_title('Confusion Matrix Gaussian Naive Bayes')
axes[0].set_xlabel('Predicted')
axes[0].set_ylabel('Actual')

sns.heatmap(conf_matrix_dt, annot=True, fmt='d', cmap='Blues', ax=axes[1])
axes[1].set_title('Confusion Matrix Decision Tree')
axes[1].set_xlabel('Predicted')
axes[1].set_ylabel('Actual')

sns.heatmap(conf_matrix_knn, annot=True, fmt='d', cmap='Blues', ax=axes[2])
axes[2].set_title('Confusion Matrix K-Nearest Neighbors')
axes[2].set_xlabel('Predicted')
axes[2].set_ylabel('Actual')

plt.tight_layout()
plt.show()

# Misalnya, X adalah fitur dan y adalah target
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=42)

# Tanpa normalisasi (Model asli)
# Inisialisasi model
gnb = GaussianNB()
dt = DecisionTreeClassifier(random_state=42)
knn = KNeighborsClassifier(n_neighbors=5)

# Latih dan evaluasi model tanpa normalisasi
gnb.fit(X_train, y_train)
dt.fit(X_train, y_train)
knn.fit(X_train, y_train)

# Prediksi dan hitung akurasi
gnb_acc = accuracy_score(y_test, gnb.predict(X_test))
dt_acc = accuracy_score(y_test, dt.predict(X_test))
knn_acc = accuracy_score(y_test, knn.predict(X_test))

print(f"Akurasi GaussianNB tanpa normalisasi: {gnb_acc:.4f}")
print(f"Akurasi Decision Tree tanpa normalisasi: {dt_acc:.4f}")
print(f"Akurasi KNN tanpa normalisasi: {knn_acc:.4f}")
print("")

# Dengan normalisasi (menggunakan StandardScaler)
scaler = StandardScaler()

# Terapkan normalisasi pada data latih dan uji
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Latih dan evaluasi model dengan normalisasi
gnb.fit(X_train_scaled, y_train)
dt.fit(X_train_scaled, y_train)
knn.fit(X_train_scaled, y_train)

# Prediksi dan hitung akurasi setelah normalisasi
gnb_scaled_acc = accuracy_score(y_test, gnb.predict(X_test_scaled))
dt_scaled_acc = accuracy_score(y_test, dt.predict(X_test_scaled))
knn_scaled_acc = accuracy_score(y_test, knn.predict(X_test_scaled))

print(f"Akurasi GaussianNB setelah di normalisasi: {gnb_scaled_acc:.4f}")
print(f"Akurasi Decision Tree setelah di normalisasi: {dt_scaled_acc:.4f}")
print(f"Akurasi KNN setelah di normalisasi: {knn_scaled_acc:.4f}")

import streamlit as st
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score
from sklearn.neighbors import KNeighborsClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.tree import DecisionTreeClassifier
import matplotlib.pyplot as plt
import seaborn as sns

# Fungsi untuk mempersiapkan model dan pelatihan
def prepare_model(model_type, X_train, y_train):
    if model_type == 'KNN':
        model = KNeighborsClassifier()
    elif model_type == 'Naive Bayes':
        model = GaussianNB()
    elif model_type == 'Decision Tree':
        model = DecisionTreeClassifier(random_state=42)
    model.fit(X_train, y_train)
    return model

# Fungsi untuk mengevaluasi model menggunakan cross-validation
def evaluate_model(model, X, y):
    accuracy = accuracy_score(model.predict(X), y)
    return accuracy

# Aplikasi Streamlit
st.title("Water Quality Potability Prediction")

# Upload file CSV
uploaded_file = st.file_uploader("Pilih file CSV", type=["csv"])

if uploaded_file is not None:
    try:
        # Membaca dataset dari file yang diunggah
        data = pd.read_csv(uploaded_file)

        st.write("Dataset Kualitas Air:")
        st.write(data.head())

        # Memeriksa apakah kolom 'Potability' ada
        if 'Potability' not in data.columns:
            st.error("Dataset tidak mengandung kolom 'Potability'.")
        else:
            # Memisahkan fitur dan target
            X = data.drop(columns=["Potability"])  # Fitur (tanpa Potability)
            y = data["Potability"]  # Target Potability

            # Menghapus baris dengan nilai NaN
            X = X.dropna()
            y = y[X.index]  # Menyesuaikan target dengan data fitur yang sudah dibersihkan

            # Memastikan tidak ada NaN di dataset
            if X.isnull().sum().any() or y.isnull().sum():
                st.error("Terdapat nilai NaN pada dataset.")
            else:
                # Menampilkan distribusi kelas Potability
                st.write("Distribusi Kelas Potability:")
                st.write(data['Potability'].value_counts())

                # Menampilkan plot distribusi kelas
                plt.figure(figsize=(6,4))
                sns.countplot(x='Potability', data=data)
                st.pyplot()

                # Membagi data menjadi training dan testing set
                X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y)

                # Normalisasi data
                scaler = StandardScaler()
                X_train_scaled = scaler.fit_transform(X_train)
                X_test_scaled = scaler.transform(X_test)

                # Menampilkan pilihan model
                model_choice = st.sidebar.selectbox("Pilih Model", ['KNN', 'Naive Bayes', 'Decision Tree'])

                # Melatih model
                st.write(f"Training Model {model_choice}...")
                model = prepare_model(model_choice, X_train_scaled, y_train)

                # Evaluasi model dengan cross-validation
                accuracy = evaluate_model(model, X_test_scaled, y_test)
                st.write(f"Akurasi Model {model_choice}: {accuracy:.4f}")

                # Fitur input untuk prediksi
                st.sidebar.header("Masukkan Fitur Baru (lebih dekat ke Potable)")
                
                # Pastikan slider menggunakan tipe data yang konsisten
                hardness = st.sidebar.slider("Hardness", 50.0, 150.0, 100.0)
                solids = st.sidebar.slider("Solids", 500.0, 1500.0, 1000.0)
                chloramines = st.sidebar.slider("Chloramines", 0.0, 3.0, 1.0)
                sulfate = st.sidebar.slider("Sulfate", 50.0, 300.0, 150.0)
                conductivity = st.sidebar.slider("Conductivity", 200.0, 800.0, 400.0)
                organic_carbon = st.sidebar.slider("Organic_carbon", 10.0, 30.0, 20.0)
                trihalomethanes = st.sidebar.slider("Trihalomethanes", 0.0, 50.0, 25.0)
                turbidity = st.sidebar.slider("Turbidity", 0.1, 2.0, 1.0)
                ph = st.sidebar.slider("pH", 6.5, 8.0, 7.2)

                # Menggabungkan semua fitur input untuk prediksi
                input_data = np.array([[hardness, solids, chloramines, sulfate, conductivity, organic_carbon, trihalomethanes, turbidity, ph]])

                # Melakukan normalisasi terhadap input data
                input_data_scaled = scaler.transform(input_data)

                # Prediksi menggunakan model
                prediction = model.predict(input_data_scaled)
                predicted_class = "Potable" if prediction[0] == 1 else "Non-Potable"
                
                # Menampilkan hasil prediksi potability di sidebar
                st.sidebar.write(f"Prediksi Potabilitas: {predicted_class}")

                # Menampilkan evaluasi model pada testing set
                y_pred = model.predict(X_test_scaled)
                test_accuracy = accuracy_score(y_test, y_pred)
                st.write(f"Akurasi Model pada Testing Set: {test_accuracy:.4f}")

    except Exception as e:
        st.error(f"Terjadi kesalahan saat memproses file: {e}")
else:
    st.write("Silakan unggah file CSV untuk memulai.")
